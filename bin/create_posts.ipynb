{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94ec8535-52fd-4ecd-9b1c-b6fdaa886950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "from itertools import islice\n",
    "from dotenv import load_dotenv\n",
    "import traceback2 as traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a471c508-6f7d-461e-8a4c-e20921e7c29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/s2mudemi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d723762-bf2b-44c5-9284-decf4464782c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0c17afc-7eca-443e-bfeb-d826122a4467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research_case.analyzers.llm_client import LLMClient\n",
    "from research_case.generators.post_generator import PostGenerator, StimulusGenerator, GenerationPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1bdd1bf-639a-4d4b-ae9e-60c67983831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b18f2db-3aa3-4931-99a8-06900cd28248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_posts_for_user(\n",
    "    user_id: str,\n",
    "    persona: Dict,\n",
    "    original_posts: List[Dict],\n",
    "    post_generator: PostGenerator,\n",
    "    stimulus_generator: StimulusGenerator,\n",
    "    posts_per_persona: int\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Generate posts for a single user and return in flat structure.\n",
    "    \n",
    "    Args:\n",
    "        user_id: User identifier\n",
    "        persona: User's persona data\n",
    "        original_posts: List of original posts\n",
    "        post_generator: PostGenerator instance\n",
    "        stimulus_generator: StimulusGenerator instance\n",
    "        posts_per_persona: Number of posts to generate\n",
    "        \n",
    "    Returns:\n",
    "        List of generated post records\n",
    "    \"\"\"\n",
    "    generated_records = []\n",
    "    timestamp = datetime.now(timezone.utc).isoformat()\n",
    "    \n",
    "    for i in range(posts_per_persona):\n",
    "        if i < len(original_posts):\n",
    "            # Extract original post content\n",
    "            original_post = original_posts[i].get('full_text', '')\n",
    "            original_post_id = original_posts[i].get('tweet_id', '')\n",
    "            original_timestamp = original_posts[i].get('created_at', '')\n",
    "            \n",
    "            # Create stimulus and generate new post\n",
    "            stimulus = stimulus_generator.create_post_stimulus(original_post)\n",
    "            prompt = GenerationPrompt(persona=persona, stimulus=stimulus)\n",
    "            generated_text = post_generator.generate_post(prompt)\n",
    "            \n",
    "            # Create flat record structure\n",
    "            record = {\n",
    "                \"user_id\": user_id,\n",
    "                \"generation_id\": f\"{user_id}_gen_{i}\",  # Unique identifier for generated post\n",
    "                \"original_post_id\": original_post_id,\n",
    "                \"original_text\": original_post,\n",
    "                \"original_timestamp\": original_timestamp,\n",
    "                \"stimulus\": stimulus,\n",
    "                \"generated_text\": generated_text,\n",
    "                \"generation_timestamp\": timestamp,\n",
    "                **{f\"persona_{k}\": v for k, v in persona.items()},\n",
    "            }\n",
    "            \n",
    "            generated_records.append(record)\n",
    "    \n",
    "    return generated_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "852d8e8c-2972-4f1c-8822-af22c69cb760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    args = {\n",
    "        \"personas\": \"research_case/data/my_experiment/personas.json\",\n",
    "        \"posts\": \"research_case/data/preprocessed/processed_users.json\",\n",
    "        \"output\": \"research_case/data/my_experiment/generated_post.json\",\n",
    "        \"posts_per_persona\": 3\n",
    "    }\n",
    "\n",
    "    # Step 2: Set up file paths\n",
    "    personas_path = args[\"personas\"]\n",
    "    posts_path = args[\"posts\"]\n",
    "    output_path = args[\"output\"] or os.path.join(\n",
    "        os.path.dirname(personas_path), \"generated_posts.json\"\n",
    "    )\n",
    "\n",
    "    # Validate input files\n",
    "    for path in [personas_path, posts_path]:\n",
    "        if not os.path.exists(path):\n",
    "            logger.error(f\"Input file not found: {path}\")\n",
    "            exit(1)\n",
    "\n",
    "    load_dotenv()\n",
    "    llm_client = LLMClient(model_name=\"llama3:70b\")\n",
    "    post_generator = PostGenerator(llm_client)\n",
    "    stimulus_generator = StimulusGenerator(llm_client)\n",
    "\n",
    "    try:\n",
    "        logger.info(\"Starting post generation...\")\n",
    "\n",
    "        # Load personas and posts\n",
    "        with open(personas_path, 'r') as f:\n",
    "            personas = json.load(f)\n",
    "        with open(posts_path, 'r') as f:\n",
    "            original_posts = json.load(f)\n",
    "\n",
    "        # Initialize results list for flat structure\n",
    "        all_generated_records = []\n",
    "\n",
    "        # Generate posts for each persona\n",
    "        for user_id, persona_variations in personas.items():\n",
    "            logger.info(f\"Generating posts for user {user_id}\")\n",
    "\n",
    "            # Get user's original posts\n",
    "            user_posts = original_posts.get(user_id, [])\n",
    "            if not user_posts:\n",
    "                logger.warning(f\"No original posts found for user {user_id}\")\n",
    "                continue\n",
    "\n",
    "            for persona_index, persona in enumerate(persona_variations):\n",
    "                logger.info(f\"  Generating posts for persona variation {persona_index + 1} for user {user_id}\")\n",
    "\n",
    "                user_records = generate_posts_for_user(\n",
    "                    user_id=user_id,\n",
    "                    persona=persona,\n",
    "                    original_posts=user_posts,\n",
    "                    post_generator=post_generator,\n",
    "                    stimulus_generator=stimulus_generator,\n",
    "                    posts_per_persona=args[\"posts_per_persona\"]\n",
    "                )\n",
    "\n",
    "                for record in user_records:\n",
    "                    record['persona_variation_index'] = persona_index + 1\n",
    "                    used_fields = list(persona.keys()) \n",
    "                    record['persona_fields_used'] = used_fields\n",
    "\n",
    "                all_generated_records.extend(user_records)\n",
    "\n",
    "        output_data = {\n",
    "            \"metadata\": {\n",
    "                \"num_users\": len(personas),\n",
    "                \"posts_per_persona\": args[\"posts_per_persona\"],\n",
    "                \"total_posts_generated\": len(all_generated_records)\n",
    "            },\n",
    "            \"generated_posts\": all_generated_records\n",
    "        }\n",
    "\n",
    "        # Save results\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(output_data, f, indent=4)\n",
    "\n",
    "        logger.info(f\"Post generation completed. Generated {len(all_generated_records)} posts.\")\n",
    "        logger.info(f\"Results saved to {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(\"Failed to generate posts:\")\n",
    "        logger.error(traceback.format_exc())\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d7a0660-949c-4aa1-8ada-854f0f9c942d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting post generation...\n",
      "INFO:__main__:Generating posts for user 254185636\n",
      "INFO:__main__:  Generating posts for persona variation 1 for user 254185636\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:  Generating posts for persona variation 2 for user 254185636\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:  Generating posts for persona variation 3 for user 254185636\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Post generation completed. Generated 9 posts.\n",
      "INFO:__main__:Results saved to research_case/data/my_experiment/generated_post.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e031dc7b-0377-4e16-9173-9f3e7c150047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f842a7-d2b2-4722-9837-f4a5aa0b5605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504d9804-3eba-47db-91f2-ad73a1ef00d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6445478d-1d36-4488-9bad-e24e37d77838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rcs24)",
   "language": "python",
   "name": "rcs24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
