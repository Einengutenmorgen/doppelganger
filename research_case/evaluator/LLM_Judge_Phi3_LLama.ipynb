{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMI4o/rIgPmjpybYB1J6iRs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Requirements:**\n","\n","*   Login to your Hugging Face account\n","*   API access key\n","*   !pip install -q transformers accelerate bitsandbytes torch\n","\n"],"metadata":{"id":"qIWeNDVCy4ul"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qghLvJ-YyqNN"},"outputs":[],"source":["#Microsoft's Phi-3-mini-4k-instruct\n","\n","import pandas as pd\n","import re\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","import torch\n","\n","MODEL_NAME = \"microsoft/Phi-3-mini-4k-instruct\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_NAME,\n","    device_map=\"auto\",\n","    torch_dtype=torch.bfloat16\n",")\n","\n","CODEBOOK = \"\"\"Evaluation Criteria (0-4 scale):\n","1. Stylistic Similarity: Grammar, vocabulary, sentence structure, tone, punctuation, capitalization, emojis, hashtags\n","2. Topic Similarity: Main subject matter and theme alignment\n","3. Sentiment Similarity: Emotional tone, intensity and attitude\n","\n","Rating Guide:\n","4 = Very Similar, 3 = Similar, 2 = Neutral, 1 = Dissimilar, 0 = Very Dissimilar\n","\"\"\"\n","\n","def format_prompt(original, synthetic):\n","    return f\"\"\"<|user|>\n","{CODEBOOK}\n","\n","Analyze this tweet pair. Provide ONLY three numerical scores (0-4) separated by commas in this exact format:\n","\"stylistic,topic,sentiment\"\n","\n","Original: {original}\n","Synthetic: {synthetic}\n","<|assistant|>\n","Scores: \"\"\"\n","\n","def evaluate_pair(original, synthetic):\n","    prompt = format_prompt(original, synthetic)\n","\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n","\n","    outputs = model.generate(\n","        **inputs,\n","        max_new_tokens=15,\n","        do_sample=False,\n","        temperature=0.01,\n","        pad_token_id=tokenizer.eos_token_id\n","    )\n","\n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    scores = re.findall(r'\\b[0-4]\\b', response.split(\"Scores: \")[-1])\n","\n","def batch_evaluate(tweet_pairs):\n","    results = []\n","    for pair in tweet_pairs:\n","        scores = evaluate_pair(pair[\"original\"], pair[\"synthetic\"])\n","        results.append({\n","            \"original\": pair[\"original\"],\n","            \"synthetic\": pair[\"synthetic\"],\n","            \"style\": scores[0],\n","            \"topic\": scores[1],\n","            \"sentiment\": scores[2]\n","        })\n","    return pd.DataFrame(results)\n","\n","def read_tweet_pairs_from_excel(file_path):\n","    \"\"\"\n","    Reads tweet pairs from an Excel file.\n","\n","    Parameters:\n","    - file_path: Path to the Excel file.\n","\n","    Returns:\n","    - A list of dictionaries containing the tweet pairs.\n","    \"\"\"\n","    try:\n","        # Read the Excel file\n","        df = pd.read_excel(file_path)\n","\n","        # Ensure the required columns exist\n","        required_columns = [\"original\", \"synthetic\"]\n","        if not all(col in df.columns for col in required_columns):\n","            raise ValueError(\"The Excel file must contain 'original' and 'synthetic' columns.\")\n","\n","        # Convert DataFrame to a list of dictionaries\n","        tweet_pairs = df.to_dict('records')\n","\n","        return tweet_pairs\n","\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","        return []\n","\n","def main():\n","    file_path = \"File_Name.xlsx\"  # Path to your Excel file\n","    tweet_pairs = read_tweet_pairs_from_excel(file_path)\n","\n","    if tweet_pairs:\n","        results_df = batch_evaluate(tweet_pairs)\n","        print(results_df)\n","\n","        # Save results to a CSV file\n","        output_file_path = \"Result.csv\"\n","        results_df.to_csv(output_file_path, index=False)\n","        print(f\"Results saved to {output_file_path}\")\n","\n","        if not results_df.empty:\n","            print(\"\\nAverage Scores:\")\n","            print(results_df[['style', 'topic', 'sentiment']].mean())\n","    else:\n","        print(\"No tweet pairs found.\")\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","source":["#Llama-3.2-1B-Instruct\n","\n","#pipeline as a high-level helper\n","from transformers import pipeline\n","\n","messages = [\n","    {\"role\": \"user\", \"content\": \"User_Prompt\"},\n","]\n","pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-1B-Instruct\")\n","pipe(messages)"],"metadata":{"id":"WbXEatwf0vOx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","from huggingface_hub import login\n","\n","# Set your Hugging Face token as an environment variable\n","os.environ[\"HUGGINGFACE_TOKEN\"] = \"TOKEN_HERE\"\n","\n","# Or login using the huggingface_hub library\n","login(token=\"TOKEN_HERE\")\n","model=\"meta-llama/Llama-3.2-1B-Instruct\"\n","# Then load the model and tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\", token=os.environ[\"HUGGINGFACE_TOKEN\"])\n","model = AutoModelForCausalLM.from_pretrained(\n","    \"meta-llama/Llama-3.2-1B-Instruct\",\n","    device_map=\"auto\",\n","    torch_dtype=torch.bfloat16,\n","    load_in_4bit=True,\n","    attn_implementation=\"sdpa\",\n","    token=os.environ[\"HUGGINGFACE_TOKEN\"]\n",")"],"metadata":{"id":"n796coO11dYw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","import torch\n","import pandas as pd\n","import re\n","\n","MODEL_NAME = \"meta-llama/Llama-3.2-1B-Instruct\"\n","DEVICE = \"cuda\"\n","\n","# Load model with 4-bit quantization for T4 compatibility\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_NAME,\n","    device_map=\"auto\",\n","    torch_dtype=torch.bfloat16,\n","    load_in_4bit=True,  # Optimize for T4's 16GB VRAM\n","    attn_implementation=\"sdpa\"  #Flash attention\n",")\n","\n","CODEBOOK = \"\"\"Evaluation Criteria (0-4):\n","1. Stylistic: Writing style elements\n","2. Topic: Main subject alignment\n","3. Sentiment: Emotional tone match\n","\n","Rating Guide:\n","4 = Very Similar, 3 = Similar, 2 = Neutral, 1 = Dissimilar, 0 = Very Dissimilar\"\"\"\n","\n","\"\"\"\n","Customize the CODEBOOK accordingly:\n","CODEBOOK = Evaluation Criteria (0-4 scale):\n","1. Stylistic Similarity: Grammar, vocabulary, sentence structure, tone, punctuation, capitalization, emojis, hashtags\n","2. Topic Similarity: Main subject matter and theme alignment\n","3. Sentiment Similarity: Emotional tone, intensity and attitude\n","\n","Rating Guide:\n","4 = Very Similar, 3 = Similar, 2 = Neutral, 1 = Dissimilar, 0 = Very Dissimilar\n","\"\"\"\n","\n","def generate_prompt(original, synthetic):\n","    return f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n","You are an expert evaluator comparing tweets. {CODEBOOK}<|eot_id|>\n","<|start_header_id|>user<|end_header_id|>\n","Original: {original}\n","Synthetic: {synthetic}\n","Provide scores as: stylistic,topic,sentiment<|eot_id|>\n","<|start_header_id|>assistant<|end_header_id|>\n","Scores: \"\"\"\n","\n","def extract_scores(response):\n","    # Find first 3 numbers between 0-4 in response\n","    numbers = re.findall(r'\\b[0-4]\\b', response)\n","    return [int(n) for n in numbers[:3]] if len(numbers)>=3 else [None]*3\n","\n","def evaluate_pair(original, synthetic):\n","    prompt = generate_prompt(original, synthetic)\n","\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n","\n","    with torch.inference_mode():\n","        outputs = model.generate(\n","            **inputs,\n","            max_new_tokens=30,\n","            temperature=0.1,\n","            do_sample=False,\n","            pad_token_id=tokenizer.eos_token_id\n","        )\n","\n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return extract_scores(response.split(\"Scores: \")[-1])\n","\n","# Batch processing function\n","def evaluate_tweets(tweet_pairs):\n","    results = []\n","    for pair in tweet_pairs:\n","        style, topic, sentiment = evaluate_pair(\n","            pair[\"original\"],\n","            pair[\"synthetic\"]\n","        )\n","        results.append({\n","            \"original\": pair[\"original\"],\n","            \"synthetic\": pair[\"synthetic\"],\n","            \"style_score\": style,\n","            \"topic_score\": topic,\n","            \"sentiment_score\": sentiment\n","        })\n","    return pd.DataFrame(results)\n","\n","def read_tweet_pairs_from_excel(file_path):\n","    \"\"\"\n","    Reads tweet pairs from an Excel file.\n","\n","    Parameters:\n","    - file_path: Path to the Excel file.\n","\n","    Returns:\n","    - A list of dictionaries containing the tweet pairs.\n","    \"\"\"\n","    try:\n","        # Read the Excel file\n","        df = pd.read_excel(file_path)\n","\n","        # Ensure the required columns exist\n","        required_columns = [\"original\", \"synthetic\"]\n","        if not all(col in df.columns for col in required_columns):\n","            raise ValueError(\"The Excel file must contain 'original' and 'synthetic' columns.\")\n","\n","        # Convert DataFrame to a list of dictionaries\n","        tweet_pairs = df.to_dict('records')\n","\n","        return tweet_pairs\n","\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","        return []\n","\n","def main():\n","    file_path = \"File_Name.xlsx\"  # Path to your Excel file\n","    tweet_pairs = read_tweet_pairs_from_excel(file_path)\n","\n","    if tweet_pairs:\n","        results_df = evaluate_tweets(tweet_pairs)\n","        print(\"Evaluation Results:\")\n","        print(results_df)\n","\n","        # Save results to a CSV file\n","        output_file_path = \"Results.csv\"\n","        results_df.to_csv(output_file_path, index=False)\n","        print(f\"Results saved to {output_file_path}\")\n","\n","        if not results_df.empty:\n","            print(\"\\nAverage Scores:\")\n","            print(results_df[['style_score', 'topic_score', 'sentiment_score']].mean())\n","    else:\n","        print(\"No tweet pairs found.\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"2f-ZtGXi26y-"},"execution_count":null,"outputs":[]}]}