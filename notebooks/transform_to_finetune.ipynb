{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/mogen/Desktop/Research_Case/notebooks\n",
      "Processing file: /Users/mogen/Desktop/Research_Case/fine_tune03/generated_posts.json\n",
      "Output will be saved to: /Users/mogen/Desktop/Research_Case/fine_tune03/fine_tune04.csv\n",
      "rows:8000\n",
      "Successfully processed 8000 records\n",
      "Output saved to: /Users/mogen/Desktop/Research_Case/fine_tune03/fine_tune04.csv\n",
      "\n",
      "First few rows of the processed data:\n",
      "                                               tweet  \\\n",
      "0  Usually, big tech companies are more than will...   \n",
      "1  Attention bolshevik dirtbags,\\n\\nSwiss researc...   \n",
      "2  Another Arraignment Day, yet Sean Hannity says...   \n",
      "3  Old school hip-hip makes celebrity net worth s...   \n",
      "4  Day 931!\\nJudge Tanya Chutkan issued a protect...   \n",
      "\n",
      "                                            stimulus  \\\n",
      "0  Comment: Discussion on the willingness of big ...   \n",
      "1  Statement: Swiss research indicates that the f...   \n",
      "2  Comment: Discussion on Sean Hannity's public s...   \n",
      "3  Comment: Comparison of net worth between a mod...   \n",
      "4  Information: Updates on legal and political ev...   \n",
      "\n",
      "                                             persona  \n",
      "0  persona_general_decription: The user is a poli...  \n",
      "1  persona_general_decription: The user is a poli...  \n",
      "2  persona_vocabulary_range: The user consistentl...  \n",
      "3  persona_vocabulary_range: The user consistentl...  \n",
      "4  persona_identity_projection: Positions as a po...  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def process_json_to_csv(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Transform JSON data into CSV with specified columns.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to input JSON file\n",
    "        output_file (str): Path to output CSV file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if input file exists\n",
    "        if not os.path.exists(input_file):\n",
    "            raise FileNotFoundError(f\"Input file '{input_file}' not found\")\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        output_dir = os.path.dirname(output_file)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            print(f\"Created output directory: {output_dir}\")\n",
    "\n",
    "        # Read the JSON file\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            # Add the missing opening brace if needed\n",
    "            if not content.startswith('{'):\n",
    "                content = '{' + content\n",
    "            data = json.loads(content)\n",
    "        \n",
    "        # Process each post\n",
    "        processed_data = []\n",
    "        for post in data['generated_posts']:\n",
    "            # Collect all persona fields\n",
    "            persona_fields = []\n",
    "            for key, value in post.items():\n",
    "                if key.startswith('persona_'):\n",
    "                    persona_fields.append(f\"{key}: {value}\")\n",
    "            \n",
    "            # Create entry with required fields\n",
    "            entry = {\n",
    "                'tweet': post['original_text'],\n",
    "                'stimulus': post['stimulus'],\n",
    "                'persona': '\\n'.join(persona_fields)\n",
    "            }\n",
    "            processed_data.append(entry)\n",
    "        \n",
    "        # Convert to DataFrame and save as CSV\n",
    "        df = pd.DataFrame(processed_data)\n",
    "        print(f'rows:{len(df)}')\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Successfully processed {len(processed_data)} records\")\n",
    "        print(f\"Output saved to: {output_file}\")\n",
    "        \n",
    "        # Display first few rows as sample\n",
    "        print(\"\\nFirst few rows of the processed data:\")\n",
    "        print(df.head())\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: Invalid JSON format - {str(e)}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Missing required field - {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An unexpected error occurred - {str(e)}\")\n",
    "        raise  # Re-raise the exception to see the full traceback\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Get current working directory\n",
    "    current_dir = os.getcwd()\n",
    "    print(f\"Current working directory: {current_dir}\")\n",
    "    \n",
    "    # Use current directory for input and output files\n",
    "    input_file = \"/Users/mogen/Desktop/Research_Case/fine_tune03/generated_posts.json\"  # Input file in current directory\n",
    "    output_file = \"/Users/mogen/Desktop/Research_Case/fine_tune03/fine_tune04.csv\"  # Output file in current directory\n",
    "    \n",
    "    print(f\"Processing file: {input_file}\")\n",
    "    print(f\"Output will be saved to: {output_file}\")\n",
    "    \n",
    "    process_json_to_csv(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/mogen/Desktop/Research_Case/notebooks\n",
      "Processing file: /Users/mogen/Desktop/Research_Case/fine_tune03/generated_posts.json\n",
      "Output will be saved to: /Users/mogen/Desktop/Research_Case/fine_tune03/fine_tune_regress.csv\n",
      "Total rows: 8000\n",
      "Successfully processed 8000 records\n",
      "Output saved to: /Users/mogen/Desktop/Research_Case/fine_tune03/fine_tune_regress.csv\n",
      "\n",
      "First few rows of the processed data:\n",
      "                                               tweet  \\\n",
      "0  Usually, big tech companies are more than will...   \n",
      "1  Attention bolshevik dirtbags,\\n\\nSwiss researc...   \n",
      "2  Another Arraignment Day, yet Sean Hannity says...   \n",
      "3  Old school hip-hip makes celebrity net worth s...   \n",
      "4  Day 931!\\nJudge Tanya Chutkan issued a protect...   \n",
      "\n",
      "                                            stimulus  \\\n",
      "0  Comment: Discussion on the willingness of big ...   \n",
      "1  Statement: Swiss research indicates that the f...   \n",
      "2  Comment: Discussion on Sean Hannity's public s...   \n",
      "3  Comment: Comparison of net worth between a mod...   \n",
      "4  Information: Updates on legal and political ev...   \n",
      "\n",
      "                                        persona_text  \\\n",
      "0  persona_general_decription: The user is a poli...   \n",
      "1  persona_general_decription: The user is a poli...   \n",
      "2  persona_vocabulary_range: The user consistentl...   \n",
      "3  persona_vocabulary_range: The user consistentl...   \n",
      "4  persona_identity_projection: Positions as a po...   \n",
      "\n",
      "                                      persona_vector  \n",
      "0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, ...  \n",
      "1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, ...  \n",
      "2  [0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, ...  \n",
      "3  [0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, ...  \n",
      "4  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
      "\n",
      "Persona field presence summary:\n",
      "general_decription: 1838 records (22.98%)\n",
      "brevity_style: 1762 records (22.02%)\n",
      "language_formality: 1820 records (22.75%)\n",
      "narrative_voice: 1822 records (22.78%)\n",
      "vocabulary_range: 1772 records (22.15%)\n",
      "punctuation_style: 1840 records (23.00%)\n",
      "controversy_handling: 1842 records (23.03%)\n",
      "community_role: 1750 records (21.88%)\n",
      "content_triggers: 1738 records (21.73%)\n",
      "reaction_patterns: 1866 records (23.33%)\n",
      "message_effectiveness: 1836 records (22.95%)\n",
      "opinion_expression: 1864 records (23.30%)\n",
      "emotional_expression: 1816 records (22.70%)\n",
      "cognitive_patterns: 1860 records (23.25%)\n",
      "social_orientation: 1862 records (23.28%)\n",
      "conflict_approach: 1820 records (22.75%)\n",
      "value_signals: 1910 records (23.88%)\n",
      "identity_projection: 1804 records (22.55%)\n",
      "belief_expression: 1844 records (23.05%)\n",
      "stress_indicators: 1736 records (21.70%)\n",
      "adaptability_signs: 1788 records (22.35%)\n",
      "authenticity_markers: 1810 records (22.62%)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define persona fields in order\n",
    "PERSONA_FIELDS = [\n",
    "    \"general_decription\",\n",
    "    \"brevity_style\",\n",
    "    \"language_formality\",\n",
    "    \"narrative_voice\",\n",
    "    \"vocabulary_range\",\n",
    "    \"punctuation_style\",\n",
    "    \"controversy_handling\",\n",
    "    \"community_role\",\n",
    "    \"content_triggers\",\n",
    "    \"reaction_patterns\",\n",
    "    \"message_effectiveness\",\n",
    "    \"opinion_expression\",\n",
    "    \"emotional_expression\",\n",
    "    \"cognitive_patterns\",\n",
    "    \"social_orientation\",\n",
    "    \"conflict_approach\",\n",
    "    \"value_signals\",\n",
    "    \"identity_projection\",\n",
    "    \"belief_expression\",\n",
    "    \"stress_indicators\",\n",
    "    \"adaptability_signs\",\n",
    "    \"authenticity_markers\"\n",
    "]\n",
    "\n",
    "def process_json_to_csv(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Transform JSON data into CSV with persona fields represented as a single vector column.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to input JSON file\n",
    "        output_file (str): Path to output CSV file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if input file exists\n",
    "        if not os.path.exists(input_file):\n",
    "            raise FileNotFoundError(f\"Input file '{input_file}' not found\")\n",
    "\n",
    "        # Create output directory if it doesn't exist\n",
    "        output_dir = os.path.dirname(output_file)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            print(f\"Created output directory: {output_dir}\")\n",
    "\n",
    "        # Read the JSON file\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            \n",
    "        # Add the missing opening brace if needed\n",
    "        if not content.startswith('{'):\n",
    "            content = '{' + content\n",
    "            \n",
    "        data = json.loads(content)\n",
    "\n",
    "        # Process each post\n",
    "        processed_data = []\n",
    "        for post in data['generated_posts']:\n",
    "            # Initialize entry with required fields\n",
    "            entry = {\n",
    "                'tweet': post['original_text'],\n",
    "                'stimulus': post['stimulus'],\n",
    "                'persona_text': ''  # Will store the full text version\n",
    "            }\n",
    "            \n",
    "            # Initialize vector for persona fields\n",
    "            persona_vector = [0] * len(PERSONA_FIELDS)\n",
    "            \n",
    "            # Collect persona fields and build vector\n",
    "            persona_texts = []\n",
    "            for key, value in post.items():\n",
    "                if key.startswith('persona_'):\n",
    "                    # Extract the field name without 'persona_' prefix\n",
    "                    field_name = key[8:]  # Remove 'persona_' prefix\n",
    "                    if field_name in PERSONA_FIELDS:\n",
    "                        # Set vector position to 1\n",
    "                        field_index = PERSONA_FIELDS.index(field_name)\n",
    "                        persona_vector[field_index] = 1\n",
    "                    persona_texts.append(f\"{key}: {value}\")\n",
    "            \n",
    "            # Add vector to entry\n",
    "            entry['persona_vector'] = str(persona_vector)  # Store as string representation\n",
    "            \n",
    "            # Join all persona texts\n",
    "            entry['persona_text'] = '\\n'.join(persona_texts)\n",
    "            processed_data.append(entry)\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(processed_data)\n",
    "\n",
    "        print(f'Total rows: {len(df)}')\n",
    "        \n",
    "        # Save to CSV\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Successfully processed {len(processed_data)} records\")\n",
    "        print(f\"Output saved to: {output_file}\")\n",
    "\n",
    "        # Display first few rows as sample\n",
    "        print(\"\\nFirst few rows of the processed data:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        # Display summary of persona field presence\n",
    "        print(\"\\nPersona field presence summary:\")\n",
    "        vector_sums = [0] * len(PERSONA_FIELDS)\n",
    "        for _, row in df.iterrows():\n",
    "            vector = eval(row['persona_vector'])  # Convert string back to list\n",
    "            for i in range(len(vector)):\n",
    "                vector_sums[i] += vector[i]\n",
    "                \n",
    "        for field, count in zip(PERSONA_FIELDS, vector_sums):\n",
    "            percentage = (count / len(df)) * 100\n",
    "            print(f\"{field}: {count} records ({percentage:.2f}%)\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: Invalid JSON format - {str(e)}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Missing required field - {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An unexpected error occurred - {str(e)}\")\n",
    "        raise  # Re-raise the exception to see the full traceback\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Get current working directory\n",
    "    current_dir = os.getcwd()\n",
    "    print(f\"Current working directory: {current_dir}\")\n",
    "\n",
    "    # Use current directory for input and output files\n",
    "    input_file = \"/Users/mogen/Desktop/Research_Case/fine_tune03/generated_posts.json\"\n",
    "    output_file = \"/Users/mogen/Desktop/Research_Case/fine_tune03/fine_tune_regress.csv\"\n",
    "    \n",
    "    print(f\"Processing file: {input_file}\")\n",
    "    print(f\"Output will be saved to: {output_file}\")\n",
    "    \n",
    "    process_json_to_csv(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows:6758\n",
      "Successfully processed 6758 records\n",
      "Output saved to: /Users/mogen/Desktop/Research_Case/fine_tune/fine_tune.csv\n",
      "\n",
      "First few rows of the processed data:\n",
      "                                               tweet  \\\n",
      "0  Support my local conservative talk show in the...   \n",
      "1  It is so sad that twitter had to self implode,...   \n",
      "2  new message from square\\nAlso, anything you pr...   \n",
      "3  She should have never resigned to calm the com...   \n",
      "4  Check out my website, I called out BLM for who...   \n",
      "\n",
      "                                            stimulus  \\\n",
      "0  Statement: Promotion of a local conservative t...   \n",
      "1  Comment: The decline of Twitter and its impact...   \n",
      "2  Information: Square's policy on content modera...   \n",
      "3  Comment: Discussion about the resignation of a...   \n",
      "4  Comment: Criticism of the Black Lives Matter m...   \n",
      "\n",
      "                                             persona  \n",
      "0  persona_narrative_voice: The user's narrative ...  \n",
      "1  persona_narrative_voice: The user's narrative ...  \n",
      "2  persona_narrative_voice: The user's narrative ...  \n",
      "3  persona_narrative_voice: The user's narrative ...  \n",
      "4  persona_narrative_voice: The user's narrative ...  \n"
     ]
    }
   ],
   "source": [
    "# Check if input file exists\n",
    "if not os.path.exists(input_file):\n",
    "    raise FileNotFoundError(f\"Input file '{input_file}' not found\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = os.path.dirname(output_file)\n",
    "if output_dir and not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Created output directory: {output_dir}\")\n",
    "\n",
    "# Read the JSON file\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "    # Add the missing opening brace if needed\n",
    "    if not content.startswith('{'):\n",
    "        content = '{' + content\n",
    "    data = json.loads(content)\n",
    "\n",
    "# Process each post\n",
    "processed_data = []\n",
    "for post in data['generated_posts']:\n",
    "    # Collect all persona fields\n",
    "    persona_fields = []\n",
    "    for key, value in post.items():\n",
    "        if key.startswith('persona_'):\n",
    "            persona_fields.append(f\"{key}: {value}\")\n",
    "    \n",
    "    # Create entry with required fields\n",
    "    entry = {\n",
    "        'tweet': post['original_text'],\n",
    "        'stimulus': post['stimulus'],\n",
    "        'persona': '\\n'.join(persona_fields)\n",
    "    }\n",
    "    processed_data.append(entry)\n",
    "\n",
    "# Convert to DataFrame and save as CSV\n",
    "df = pd.DataFrame(processed_data)\n",
    "print(f'rows:{len(df)}')\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Successfully processed {len(processed_data)} records\")\n",
    "print(f\"Output saved to: {output_file}\")\n",
    "\n",
    "# Display first few rows as sample\n",
    "print(\"\\nFirst few rows of the processed data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persona_opinion_expression: The user shares viewpoints assertively, often with a hint of sarcasm or humor. They seem to engage with topics critically, questioning norms and highlighting issues, such as media transparency and prison call charges. Their opinions are often presented with an expectation of accountability or transparency, as seen in their call for media to investigate governmental actions.\n",
      "persona_authenticity_markers: The user's communication appears genuine and driven by personal experiences or observations. They display a consistent tone of skepticism and advocacy, particularly when addressing social justice issues. Their posts suggest a willingness to challenge systems and highlight inefficiencies, indicating a commitment to authenticity and truthfulness.\n",
      "persona_punctuation_style: The user employs a straightforward punctuation style, using commas and periods effectively to convey clear thoughts. They do not rely on excessive punctuation, such as exclamation marks, to make their points. The use of ampersands and abbreviations suggests a casual yet informed communication style.\n",
      "persona_message_effectiveness: The user conveys their points effectively, often provoking thought or action. Their posts are concise and packed with information, likely engaging those interested in social issues. They manage to communicate complex ideas simply, as seen in their critique of prison call charges and media transparency.\n",
      "persona_vocabulary_range: The user's vocabulary is varied, incorporating both casual language and more specific terms related to social justice and policy. They use humor and cultural references to make their points relatable, while also addressing serious topics with appropriate terminology. This range suggests an ability to adapt language to different contexts and audiences.\n",
      "persona_conflict_approach: The user appears to take a direct and assertive approach when addressing disagreements, as seen in their stance on educational content. They focus on expressing their opinion clearly, indicating a preference for decisive action when they believe something is inappropriate.\n",
      "persona_language_formality: The language used is a blend of formal and informal tones. Formality is evident in official announcements and calls to action, while a more casual tone is adopted in personal and community-oriented messages, such as wishing a good weekend or supporting a charity.\n",
      "persona_punctuation_style: The user employs straightforward punctuation, utilizing exclamation points for emphasis and engagement, as seen in encouraging voting and supporting charities. They also use hashtags and mentions effectively to connect with broader conversations and specific organizations.\n",
      "persona_value_signals: The user values civic engagement, community support, and educational standards. They emphasize the importance of voting, supporting charitable causes, and maintaining certain expectations in educational institutions.\n",
      "persona_cognitive_patterns: The user's cognitive patterns reflect a pragmatic and action-oriented mindset. They focus on practical outcomes, such as encouraging voting participation and supporting specific causes. Their thinking style is goal-driven, as they aim to influence and motivate their audience toward specific actions.\n",
      "persona_conflict_approach: The user appears to take a direct and assertive approach when addressing disagreements, as seen in their stance on educational content. They focus on expressing their opinion clearly, indicating a preference for decisive action when they believe something is inappropriate.\n",
      "persona_language_formality: The language used is a blend of formal and informal tones. Formality is evident in official announcements and calls to action, while a more casual tone is adopted in personal and community-oriented messages, such as wishing a good weekend or supporting a charity.\n",
      "persona_punctuation_style: The user employs straightforward punctuation, utilizing exclamation points for emphasis and engagement, as seen in encouraging voting and supporting charities. They also use hashtags and mentions effectively to connect with broader conversations and specific organizations.\n",
      "persona_value_signals: The user values civic engagement, community support, and educational standards. They emphasize the importance of voting, supporting charitable causes, and maintaining certain expectations in educational institutions.\n",
      "persona_cognitive_patterns: The user's cognitive patterns reflect a pragmatic and action-oriented mindset. They focus on practical outcomes, such as encouraging voting participation and supporting specific causes. Their thinking style is goal-driven, as they aim to influence and motivate their audience toward specific actions.\n",
      "persona_conflict_approach: The user appears to take a direct and assertive approach when addressing disagreements, as seen in their stance on educational content. They focus on expressing their opinion clearly, indicating a preference for decisive action when they believe something is inappropriate.\n",
      "persona_language_formality: The language used is a blend of formal and informal tones. Formality is evident in official announcements and calls to action, while a more casual tone is adopted in personal and community-oriented messages, such as wishing a good weekend or supporting a charity.\n",
      "persona_punctuation_style: The user employs straightforward punctuation, utilizing exclamation points for emphasis and engagement, as seen in encouraging voting and supporting charities. They also use hashtags and mentions effectively to connect with broader conversations and specific organizations.\n",
      "persona_value_signals: The user values civic engagement, community support, and educational standards. They emphasize the importance of voting, supporting charitable causes, and maintaining certain expectations in educational institutions.\n",
      "persona_cognitive_patterns: The user's cognitive patterns reflect a pragmatic and action-oriented mindset. They focus on practical outcomes, such as encouraging voting participation and supporting specific causes. Their thinking style is goal-driven, as they aim to influence and motivate their audience toward specific actions.\n"
     ]
    }
   ],
   "source": [
    "liste=list(df['persona'][-5:-1])\n",
    "for l in liste:\n",
    "    print(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
