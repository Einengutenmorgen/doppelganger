{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to /Users/mogen/Desktop/Research_Case/results/Final_finetune/03_categories.csv\n",
      "Total records processed: 50\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import re\n",
    "\n",
    "posts_file = \"/Users/mogen/Desktop/Research_Case/results/Run_o3_categories/generated_posts.json\"  # Change to your actual filename\n",
    "personas_file = \"/Users/mogen/Desktop/Research_Case/results/Run_o3_categories/personas.json\"  # Change to your actual filename\n",
    "output_file = \"/Users/mogen/Desktop/Research_Case/results/Final_finetune/03_categories.csv\"\n",
    "# Read the JSON data from files\n",
    "with open(posts_file, 'r', encoding='utf-8') as f:\n",
    "    posts_data = json.load(f)\n",
    "\n",
    "with open(personas_file, 'r', encoding='utf-8') as f:\n",
    "    personas_data = json.load(f)\n",
    "\n",
    "# Extract the generated posts\n",
    "generated_posts = posts_data.get(\"generated_posts\", [])\n",
    "\n",
    "# Prepare the output data\n",
    "output_rows = []\n",
    "\n",
    "# Process each post\n",
    "for post in generated_posts:\n",
    "    user_id = post.get(\"user_id\")\n",
    "    \n",
    "    # Get persona data for this user\n",
    "    persona_data = personas_data.get(user_id, {})\n",
    "    \n",
    "    # Get the original tweet text directly (no need to parse it as JSON)\n",
    "    tweet_text = post.get(\"original_text\", \"\")\n",
    "    \n",
    "    # Get the stimulus\n",
    "    stimulus = post.get(\"stimulus\", \"\")\n",
    "    \n",
    "    # Count persona fields\n",
    "    persona_field_count = 0\n",
    "    for field, value in persona_data.items():\n",
    "        if value and isinstance(value, str) and value.strip():\n",
    "            persona_field_count += 1\n",
    "    \n",
    "    # Create a summary of the persona (include all fields with their keys)\n",
    "    persona_summary = \"\"\n",
    "    for field, value in persona_data.items():\n",
    "        if value and isinstance(value, str) and value.strip():\n",
    "            # Add the field name and its full value\n",
    "            persona_summary += f\"{field}: {value}; \"\n",
    "    \n",
    "    # Add row to output\n",
    "    output_rows.append({\n",
    "        \"Tweet\": tweet_text,\n",
    "        \"Persona\": persona_summary,\n",
    "        \"Stimulus\": stimulus,\n",
    "        \"Number of Persona Fields\": persona_field_count\n",
    "    })\n",
    "\n",
    "# Write to CSV\n",
    "with open(output_file, 'w', encoding='utf-8', newline='') as f:\n",
    "    fieldnames = [\"Tweet\", \"Persona\", \"Stimulus\", \"Number of Persona Fields\"]\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_rows)\n",
    "\n",
    "print(f\"Combined data saved to {output_file}\")\n",
    "print(f\"Total records processed: {len(output_rows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame shape: (14851, 4)\n",
      "Number of duplicate rows: 20\n",
      "Combined DataFrame saved to '/Users/mogen/Desktop/Research_Case/results/Final_finetune/combined_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have 4 DataFrames: df1, df2, df3, df4\n",
    "import pandas as pd\n",
    "# If you need to load them from files, uncomment and modify these lines:\n",
    "df1 = pd.read_csv('/Users/mogen/Desktop/Research_Case/results/Final_finetune/03_categories.csv')\n",
    "df2 = pd.read_csv('/Users/mogen/Desktop/Research_Case/results/Final_finetune/03_open_des.csv')\n",
    "df3 = pd.read_csv('/Users/mogen/Desktop/Research_Case/results/Final_finetune/fine_tune.csv')\n",
    "df4 = pd.read_csv('/Users/mogen/Desktop/Research_Case/results/Final_finetune/fine_tune03.csv')\n",
    "\n",
    "# List of all the DataFrames\n",
    "dfs = [df1, df2, df3, df4]\n",
    "\n",
    "# Combine all DataFrames into one\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Reset the index to have a clean sequential index\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check the shape of the combined DataFrame\n",
    "print(f\"Combined DataFrame shape: {combined_df.shape}\")\n",
    "\n",
    "# Check for duplicate rows (optional)\n",
    "duplicate_count = combined_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "\n",
    "# Remove duplicates if needed\n",
    "combined_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df.to_csv('/Users/mogen/Desktop/Research_Case/results/Final_finetune/combined_data.csv', index=False)\n",
    "\n",
    "print(\"Combined DataFrame saved to '/Users/mogen/Desktop/Research_Case/results/Final_finetune/combined_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current distribution of number of persona fields:\n",
      "Number of Persona Fields\n",
      "5     14738\n",
      "13       50\n",
      "21       43\n",
      "Name: count, dtype: int64\n",
      "Target count per category: ~2471\n",
      "\n",
      "New distribution of number of persona fields:\n",
      "Adjusted Number of Fields\n",
      "3    2473\n",
      "4    2471\n",
      "5    2472\n",
      "6    2481\n",
      "7    2485\n",
      "8    2449\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Adjusted DataFrame saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "\n",
    "# Step 1: Load the combined DataFrame\n",
    "combined_df = pd.read_csv('/Users/mogen/Desktop/Research_Case/results/Final_finetune/combined_data.csv')\n",
    "\n",
    "# Step 2: Check the current distribution of persona fields\n",
    "print(\"Current distribution of number of persona fields:\")\n",
    "print(combined_df['Number of Persona Fields'].value_counts().sort_index())\n",
    "\n",
    "# Step 3: Define our target distribution between 3 and 8 fields\n",
    "# We want roughly equal numbers for each category\n",
    "total_rows = len(combined_df)\n",
    "target_count_per_category = total_rows // 6  # 6 categories (3,4,5,6,7,8)\n",
    "print(f\"Target count per category: ~{target_count_per_category}\")\n",
    "\n",
    "# Step 4: Create a function to adjust the number of fields in a persona string\n",
    "def adjust_persona_fields(persona_str, target_num_fields):\n",
    "    # Split the persona string into individual fields\n",
    "    fields = re.split(r';\\s*', persona_str.strip())\n",
    "    fields = [f for f in fields if f]  # Remove empty fields\n",
    "    \n",
    "    current_num_fields = len(fields)\n",
    "    \n",
    "    # If we need to reduce fields\n",
    "    if current_num_fields > target_num_fields:\n",
    "        # Randomly select fields to keep\n",
    "        selected_fields = random.sample(fields, target_num_fields)\n",
    "        return '; '.join(selected_fields) + ';'\n",
    "    \n",
    "    # If we need to add fields\n",
    "    elif current_num_fields < target_num_fields:\n",
    "        # Calculate how many fields to add\n",
    "        fields_to_add = target_num_fields - current_num_fields\n",
    "        \n",
    "        # Duplicate some existing fields with slightly modified text\n",
    "        extra_fields = []\n",
    "        for _ in range(fields_to_add):\n",
    "            if fields:  # Make sure we have fields to duplicate\n",
    "                field_to_duplicate = random.choice(fields)\n",
    "                field_parts = field_to_duplicate.split(': ', 1)\n",
    "                \n",
    "                if len(field_parts) == 2:\n",
    "                    key, value = field_parts\n",
    "                    # Create a new field with a slightly modified key\n",
    "                    new_key = key + \"_extended\"\n",
    "                    extra_fields.append(f\"{new_key}: {value}\")\n",
    "            \n",
    "        # Add the new fields\n",
    "        all_fields = fields + extra_fields\n",
    "        return '; '.join(all_fields) + ';'\n",
    "    \n",
    "    # If already at target, return as is\n",
    "    else:\n",
    "        return persona_str\n",
    "\n",
    "# Step 5: Create a new column for the target number of fields\n",
    "# Distribute target field counts evenly between 3 and 8\n",
    "target_distribution = []\n",
    "for i in range(3, 9):  # 3,4,5,6,7,8\n",
    "    target_distribution.extend([i] * target_count_per_category)\n",
    "\n",
    "# If we have more rows than our distribution covers, repeat the pattern\n",
    "while len(target_distribution) < total_rows:\n",
    "    target_distribution.append(random.randint(3, 8))\n",
    "\n",
    "# Shuffle the distribution and trim if needed\n",
    "random.shuffle(target_distribution)\n",
    "target_distribution = target_distribution[:total_rows]\n",
    "\n",
    "combined_df['Target Number of Fields'] = target_distribution\n",
    "\n",
    "# Step 6: Apply the adjustment function to each row\n",
    "combined_df['Adjusted Persona'] = combined_df.apply(\n",
    "    lambda row: adjust_persona_fields(row['Persona'], row['Target Number of Fields']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Step 7: Verify the new distribution\n",
    "# Count fields in the adjusted persona strings\n",
    "def count_fields(persona_str):\n",
    "    fields = re.split(r';\\s*', persona_str.strip())\n",
    "    return len([f for f in fields if f])\n",
    "\n",
    "combined_df['Adjusted Number of Fields'] = combined_df['Adjusted Persona'].apply(count_fields)\n",
    "\n",
    "print(\"\\nNew distribution of number of persona fields:\")\n",
    "print(combined_df['Adjusted Number of Fields'].value_counts().sort_index())\n",
    "\n",
    "# Step 8: Save the adjusted DataFrame\n",
    "combined_df.to_csv('/Users/mogen/Desktop/Research_Case/results/Final_finetune/adjusted_persona_data.csv', index=False)\n",
    "\n",
    "print(\"\\nAdjusted DataFrame saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"length_of_post: Posts are typically concise, often consisting of brief narratives or summaries of historical events, accompanied by open-ended questions or calls for reflection. There is a balance between informative content and engaging prompts, with a preference for medium-length posts that are easily digestible.; interests_hobbies: The user has a strong interest in history, cultural artifacts, and notable historical figures across various timelines and regions. There is a consistent pattern of sharing stories about historical events, curiosities, and achievements, indicating a deep engagement with historical exploration.; humor_style: The user exhibits a diverse sense of humor, often leaning towards historical irony and light-hearted commentary on unusual historical events, such as the 'Great Emu War' and 'Wanksy' graffiti. There is a playful engagement with historical anecdotes and occasional use of rhetorical questions to provoke thought.; demographic_indicators: The user's content suggests a background in history or cultural studies, possibly indicating an academic or educational profession. The focus on historical events and cultural artifacts suggests a well-educated individual with a passion for storytelling.;\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/mogen/Desktop/Research_Case/results/Final_finetune/adjusted_persona_data.csv'\n",
    "df= pd.read_csv(path)\n",
    "\n",
    "df['Adjusted Persona'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['Target Number of Fields','Number of Persona Fields', 'Persona' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stimulus</th>\n",
       "      <th>Adjusted Persona</th>\n",
       "      <th>Adjusted Number of Fields</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A drum solo by 18-year-old Karen Carpenter, 19...</td>\n",
       "      <td>A social media post highlighting a performance...</td>\n",
       "      <td>length_of_post: Posts are typically concise, o...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You're doing a disservice by diluting what con...</td>\n",
       "      <td>A post discussing the interpretation of certai...</td>\n",
       "      <td>interests_hobbies: The user is deeply interest...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decent odds you end up with a 100% non white b...</td>\n",
       "      <td>A post discussing diversity and representation...</td>\n",
       "      <td>cultural_context: The user is influenced by co...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twitter hacker and crypto scammer sentenced to...</td>\n",
       "      <td>A post about a legal sentencing related to cyb...</td>\n",
       "      <td>length_of_post: Posts are typically short and ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$760 billion in PPP loans were forgiven.\\n\\nTh...</td>\n",
       "      <td>A post discussing financial relief programs an...</td>\n",
       "      <td>social_dynamics: The user is an active partici...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  A drum solo by 18-year-old Karen Carpenter, 19...   \n",
       "1  You're doing a disservice by diluting what con...   \n",
       "2  Decent odds you end up with a 100% non white b...   \n",
       "3  Twitter hacker and crypto scammer sentenced to...   \n",
       "4  $760 billion in PPP loans were forgiven.\\n\\nTh...   \n",
       "\n",
       "                                            Stimulus  \\\n",
       "0  A social media post highlighting a performance...   \n",
       "1  A post discussing the interpretation of certai...   \n",
       "2  A post discussing diversity and representation...   \n",
       "3  A post about a legal sentencing related to cyb...   \n",
       "4  A post discussing financial relief programs an...   \n",
       "\n",
       "                                    Adjusted Persona  \\\n",
       "0  length_of_post: Posts are typically concise, o...   \n",
       "1  interests_hobbies: The user is deeply interest...   \n",
       "2  cultural_context: The user is influenced by co...   \n",
       "3  length_of_post: Posts are typically short and ...   \n",
       "4  social_dynamics: The user is an active partici...   \n",
       "\n",
       "   Adjusted Number of Fields  \n",
       "0                          4  \n",
       "1                          7  \n",
       "2                          3  \n",
       "3                          7  \n",
       "4                          8  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stimulus</th>\n",
       "      <th>persona</th>\n",
       "      <th>N_fields</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A drum solo by 18-year-old Karen Carpenter, 19...</td>\n",
       "      <td>A social media post highlighting a performance...</td>\n",
       "      <td>length_of_post: Posts are typically concise, o...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You're doing a disservice by diluting what con...</td>\n",
       "      <td>A post discussing the interpretation of certai...</td>\n",
       "      <td>interests_hobbies: The user is deeply interest...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decent odds you end up with a 100% non white b...</td>\n",
       "      <td>A post discussing diversity and representation...</td>\n",
       "      <td>cultural_context: The user is influenced by co...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twitter hacker and crypto scammer sentenced to...</td>\n",
       "      <td>A post about a legal sentencing related to cyb...</td>\n",
       "      <td>length_of_post: Posts are typically short and ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$760 billion in PPP loans were forgiven.\\n\\nTh...</td>\n",
       "      <td>A post discussing financial relief programs an...</td>\n",
       "      <td>social_dynamics: The user is an active partici...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  A drum solo by 18-year-old Karen Carpenter, 19...   \n",
       "1  You're doing a disservice by diluting what con...   \n",
       "2  Decent odds you end up with a 100% non white b...   \n",
       "3  Twitter hacker and crypto scammer sentenced to...   \n",
       "4  $760 billion in PPP loans were forgiven.\\n\\nTh...   \n",
       "\n",
       "                                            Stimulus  \\\n",
       "0  A social media post highlighting a performance...   \n",
       "1  A post discussing the interpretation of certai...   \n",
       "2  A post discussing diversity and representation...   \n",
       "3  A post about a legal sentencing related to cyb...   \n",
       "4  A post discussing financial relief programs an...   \n",
       "\n",
       "                                             persona  N_fields  \n",
       "0  length_of_post: Posts are typically concise, o...         4  \n",
       "1  interests_hobbies: The user is deeply interest...         7  \n",
       "2  cultural_context: The user is influenced by co...         3  \n",
       "3  length_of_post: Posts are typically short and ...         7  \n",
       "4  social_dynamics: The user is an active partici...         8  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.rename(columns={\"Adjusted Persona\": \"persona\", \"Adjusted Number of Fields\": \"N_fields\"})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14831"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/mogen/Desktop/Research_Case/results/Final_finetune/14831r_3bis8P_randomsample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
