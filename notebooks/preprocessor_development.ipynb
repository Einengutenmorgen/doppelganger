{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessor Development and Testing\n",
    "\n",
    "This notebook is for developing and testing the DataPreprocessor class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "from typing import Tuple, Dict\n",
    "from datetime import datetime\n",
    "import unittest\n",
    "import tempfile\n",
    "\n",
    "# Third-party packages\n",
    "import pandas as pd\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/mogen/Desktop/Research_Case\n",
      "Added to sys.path: /Users/mogen/Desktop/Research_Case\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the parent directory (Research_Case root)\n",
    "project_root = os.path.dirname(os.getcwd())  # This gets parent of notebooks directory\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Add to Python path if not already there\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Added to sys.path: {project_root}\")\n",
    "\n",
    "from research_case.processors.preprocess import DataPreprocessor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = {\n",
    "        'full_text': [\n",
    "            'This is a normal tweet with content',\n",
    "            'https://example.com',  # URL only\n",
    "            '@user1 @user2',  # Mentions only\n",
    "            'ðŸŽ‰ ðŸŽŠ ðŸŽˆ',  # Emojis only\n",
    "            'Short',  # Too short\n",
    "            'This is a valid tweet with a link https://example.com',\n",
    "            'Reply to someone with good content'  # Valid reply\n",
    "        ],\n",
    "        'tweet_id': [1, 2, 3, 4, 5, 6, 7],\n",
    "        'created_at': [\n",
    "            '2024-01-01 10:00:00',\n",
    "            '2024-01-01 10:01:00',\n",
    "            '2024-01-01 10:02:00',\n",
    "            '2024-01-01 10:03:00',\n",
    "            '2024-01-01 10:04:00',\n",
    "            '2024-01-01 10:05:00',\n",
    "            '2024-01-01 10:06:00'\n",
    "        ],\n",
    "        'screen_name': [\n",
    "            'user1', 'user2', 'user3', 'user4', \n",
    "            'user5', 'user6', 'user7'\n",
    "        ],\n",
    "        'original_user_id': [\n",
    "            101, 102, 103, 104, 105, 106, 107\n",
    "        ],\n",
    "        'retweeted_user_ID': [\n",
    "            None, None, None, None, None, None, None\n",
    "        ],\n",
    "        'collected_at': [\n",
    "            '2024-12-21 16:00:00',\n",
    "            '2024-12-21 16:00:00',\n",
    "            '2024-12-21 16:00:00',\n",
    "            '2024-12-21 16:00:00',\n",
    "            '2024-12-21 16:00:00',\n",
    "            '2024-12-21 16:00:00',\n",
    "            '2024-12-21 16:00:00'\n",
    "        ],\n",
    "        'reply_to_id': [\n",
    "            None, None, 123, None, None, None, 456\n",
    "        ],\n",
    "        'reply_to_user': [\n",
    "            None, None, '@original_user', None, None, None, '@another_user'\n",
    "        ],\n",
    "        'expandedURL': [\n",
    "            None, 'https://example.com', None, None, None, \n",
    "            'https://example.com', None\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "   \n",
    "df = pd.DataFrame(sample_data)\n",
    "df.to_csv('/Users/mogen/Desktop/Research_Case/research_case/test/test_data/sample_tweets.csv', index=False)\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = DataPreprocessor('/Users/mogen/Desktop/Research_Case/research_case/test/test_data/sample_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 16:13:26,871 - INFO - Loading data from /Users/mogen/Desktop/Research_Case/research_case/test/test_data/sample_tweets.csv\n",
      "2024-12-21 16:13:26,874 - INFO - Loaded 7 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (7, 10)\n"
     ]
    }
   ],
   "source": [
    "# Test loading data\n",
    "preprocessor.load_data()\n",
    "print(\"Initial data shape:\", preprocessor.df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 16:13:27,010 - INFO - Split data into 5 posts and 2 replies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts shape: (5, 10)\n",
      "Replies shape: (2, 10)\n"
     ]
    }
   ],
   "source": [
    "# Test splitting posts and replies\n",
    "posts_df, replies_df = preprocessor.split_posts_replies()\n",
    "print(\"Posts shape:\", posts_df.shape)\n",
    "print(\"Replies shape:\", replies_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered posts:\n",
      "                                           full_text\n",
      "0                This is a normal tweet with content\n",
      "5  This is a valid tweet with a link https://exam...\n"
     ]
    }
   ],
   "source": [
    "# Test tweet filtering\n",
    "filtered_posts = preprocessor.filter_tweets(posts_df)\n",
    "print(\"\\nFiltered posts:\")\n",
    "print(filtered_posts[['full_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 16:14:56,192 - INFO - Created output directory: Tests/test_data_20241221_161456\n",
      "2024-12-21 16:14:56,195 - INFO - Split data into 5 posts and 2 replies\n",
      "2024-12-21 16:14:56,195 - INFO - Filtering posts...\n",
      "2024-12-21 16:14:56,196 - INFO - Retained 2 valid posts after filtering\n",
      "2024-12-21 16:14:56,197 - INFO - Filtering replies...\n",
      "2024-12-21 16:14:56,197 - INFO - Retained 1 valid replies after filtering\n",
      "2024-12-21 16:14:56,198 - INFO - Grouping posts by user ID\n",
      "2024-12-21 16:14:56,200 - INFO - Grouped posts for 2 unique users\n",
      "2024-12-21 16:14:56,201 - INFO - Grouping conversations\n",
      "2024-12-21 16:14:56,201 - INFO - Grouped 1 conversations\n",
      "2024-12-21 16:14:56,204 - INFO - Saved all processed files to Tests/test_data_20241221_161456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed files saved to:\n",
      "Tests/test_data_20241221_161456/test_posts.csv\n",
      "Tests/test_data_20241221_161456/test_replies.csv\n"
     ]
    }
   ],
   "source": [
    "# Test full processing pipeline\n",
    "posts_file, replies_file, users_file, conversations_file = preprocessor.process(test=True)\n",
    "print(f\"\\nProcessed files saved to:\\n{posts_file}\\n{replies_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed test file: Tests/test_data_20241221_161456/test_posts.csv\n",
      "Removed test file: Tests/test_data_20241221_161456/test_replies.csv\n",
      "Removed test file: Tests/test_data_20241221_161456/test_users.json\n",
      "Removed test file: Tests/test_data_20241221_161456/test_conversations.json\n",
      "Removed empty test directory: Tests/test_data_20241221_161456\n"
     ]
    }
   ],
   "source": [
    "def cleanup_test_files(posts_file: str, replies_file: str, users_file: str, conversations_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Clean up test files and directories after testing.\n",
    "    \n",
    "    Args:\n",
    "        posts_file: Path to the test posts CSV file\n",
    "        replies_file: Path to the test replies CSV file\n",
    "        users_file: Path to the test users JSON file\n",
    "        conversations_file: Path to the test conversations JSON file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the test directory from the posts file path\n",
    "        test_dir = os.path.dirname(posts_file)\n",
    "        \n",
    "        # List all files to clean up\n",
    "        files_to_remove = [\n",
    "            posts_file,\n",
    "            replies_file, \n",
    "            users_file,\n",
    "            conversations_file\n",
    "        ]\n",
    "        \n",
    "        # Remove individual files\n",
    "        for file_path in files_to_remove:\n",
    "            if file_path and os.path.exists(file_path):\n",
    "                os.remove(file_path)\n",
    "                print(f\"Removed test file: {file_path}\")\n",
    "        \n",
    "        # Remove the test directory if it's empty\n",
    "        if os.path.exists(test_dir) and not os.listdir(test_dir):\n",
    "            os.rmdir(test_dir)\n",
    "            print(f\"Removed empty test directory: {test_dir}\")\n",
    "            \n",
    "            # Try to remove parent \"Tests\" directory if it's empty\n",
    "            parent_dir = os.path.dirname(test_dir)\n",
    "            if os.path.basename(parent_dir) == \"Tests\" and not os.listdir(parent_dir):\n",
    "                os.rmdir(parent_dir)\n",
    "                print(f\"Removed empty Tests directory: {parent_dir}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error during cleanup: {e}\")\n",
    "\n",
    "# Usage example:\n",
    "try:\n",
    "    # Run your test code\n",
    "    #print(f\"Test files are at:\\n{test_posts_file}\\n{test_replies_file}\")\n",
    "    \n",
    "    # Clean up after testing\n",
    "    cleanup_test_files(posts_file, replies_file, users_file, conversations_file)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research_Case",
   "language": "python",
   "name": "research_case"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
